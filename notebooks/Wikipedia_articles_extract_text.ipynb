{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wikipedia articles extract text",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMfY3afQbG/NwApnfYgOzKf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacomyma/mapping-controversies/blob/main/notebooks/Wikipedia_articles_extract_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üçæ Wikipedia articles extract text"
      ],
      "metadata": {
        "id": "cZJFVyoW9yDA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Input:** a list of Wikipedia articles (CSV).\n",
        "\n",
        "**Output:** a list of Wikipedia articles with text (CSV).\n",
        "\n",
        "This scripts queries Wikipedia for each article of the input list. It retrieves their text content. It saves the enriched list. It is slow."
      ],
      "metadata": {
        "id": "Wr1ZJZMZ906-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to use"
      ],
      "metadata": {
        "id": "eFanzia_-h21"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Put your input file in the same folder as the notebook\n",
        "1. Edit the settings if needed\n",
        "1. Run all the cells\n",
        "1. Take the output file from the notebook folder"
      ],
      "metadata": {
        "id": "i45GqGl8-iTe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SETTINGS"
      ],
      "metadata": {
        "id": "L_bIAuRi-pHP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input file\n",
        "input_file = \"wikipedia-articles.csv\"\n",
        "\n",
        "# Which column contains the article title?\n",
        "article_name_column = \"Article\"\n",
        "\n",
        "# Output file\n",
        "output_file = \"wikipedia-articles-with-text.csv\""
      ],
      "metadata": {
        "id": "4dJwrles-uyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SCRIPT"
      ],
      "metadata": {
        "id": "B72szco7-p0t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install and import libraries\n",
        "This notebook draws on existing code.\n",
        "You can ignore the output."
      ],
      "metadata": {
        "id": "tPv4_WMS-r-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  import wikipediaapi\n",
        "  print(\"Wikipedia api library has been imported\")\n",
        "except:\n",
        "  print(\"wikipedia api library not found. Installing...\")\n",
        "  !pip install wikipedia-api\n",
        "  \n",
        "  try:\n",
        "    import wikipediaapi\n",
        "  except:\n",
        "    print(\"Something went wrong in the installation of the wikipedia api library. Please check your internet connection and consult output from the installation below\")\n",
        "\n",
        "# Install (if needed)\n",
        "!pip install pandas\n",
        "\n",
        "# Import\n",
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "print(\"Done.\")"
      ],
      "metadata": {
        "id": "AKSwRUSL-0Vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read the input file"
      ],
      "metadata": {
        "id": "-snp-5hA_MIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "article_df = pd.read_csv(input_file, quotechar='\"', encoding='utf8', doublequote=True, quoting=csv.QUOTE_NONNUMERIC, dtype=object)\n",
        "print(\"Preview of the article list:\")\n",
        "article_df"
      ],
      "metadata": {
        "id": "g20N4_Iu-3Jz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Harvest Wikipedia"
      ],
      "metadata": {
        "id": "aPSTiAQO_M2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Language\n",
        "lan = \"en\"\n",
        "\n",
        "# Query object\n",
        "wiki_wiki = wikipediaapi.Wikipedia(\n",
        "  language=lan,\n",
        "  extract_format=wikipediaapi.ExtractFormat.WIKI\n",
        ")\n",
        "\n",
        "# Harvest\n",
        "article_text_list = []\n",
        "seen = []\n",
        "print(\"Harvesting text from \"+str(len(article_df.index))+\" wikipedia pages. This might take a while...\")\n",
        "count=1\n",
        "for index, row in article_df.iterrows():\n",
        "  title = row[article_name_column]\n",
        "  if count % 10 == 0:\n",
        "    print(\"Text harvested from \"+str(count)+\" pages out of \"+str(len(article_df.index))+\". Continuing...\")\n",
        "  if not title in seen: # Do not harvest twice the same...\n",
        "    seen.append(title)\n",
        "    try:\n",
        "      p_wiki = wiki_wiki.page(title)\n",
        "      page_text = p_wiki.text.lower()\n",
        "      new_row = {**row, 'Text': page_text}\n",
        "      article_text_list.append(new_row)\n",
        "    except:\n",
        "        print('SKIPPED: '+title+' (an error occurred)')\n",
        "  count=count+1\n",
        "\n",
        "text_articles_df = pd.DataFrame(article_text_list)\n",
        "print(\"Done.\")\n",
        "print(\"Preview of the article list with text:\")\n",
        "text_articles_df"
      ],
      "metadata": {
        "id": "ypcfiCW8_I_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save as CSV"
      ],
      "metadata": {
        "id": "9PucQUBNAuJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  text_articles_df.to_csv(output_file, index = False, encoding='utf-8')\n",
        "  print(\"Done.\")\n",
        "except IOError:\n",
        "  print(\"/!\\ Error while writing the output file\")"
      ],
      "metadata": {
        "id": "cNe-8R--AZSW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}