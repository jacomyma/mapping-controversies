{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wikipedia articles to edits list",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPmEBkpTGDdwWQscKZ5rhim",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacomyma/mapping-controversies/blob/main/notebooks/Wikipedia_articles_to_edits_list.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üçπ Wikipedia articles to edits list"
      ],
      "metadata": {
        "id": "J0Sr179sYEKo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Input:** a list of Wikipedia articles (CSV).\n",
        "\n",
        "**Output:** a list of edits (CSV).\n",
        "\n",
        "This scripts queries Wikipedia for the list of edits (i.e. revisions) for each article of the input list. It also reports the data about articles, so avoid heavy data such as article summary in the input file. You may ignore that data in settings. It's quite slow."
      ],
      "metadata": {
        "id": "UC5LToKXYJpY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to use"
      ],
      "metadata": {
        "id": "mtRw0Yh8YYLd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Put your input file in the same folder as the notebook\n",
        "1. Edit the settings if needed\n",
        "1. Run all the cells\n",
        "1. Take the output file from the notebook folder"
      ],
      "metadata": {
        "id": "laN_kVbNYYm7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SETTINGS"
      ],
      "metadata": {
        "id": "kN6XuSe_dsMs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNi1By5NYCcs"
      },
      "outputs": [],
      "source": [
        "# Input file\n",
        "input_file = \"wikipedia-articles.csv\"\n",
        "\n",
        "# Which column contains the article title?\n",
        "article_name_column = \"Article\"\n",
        "\n",
        "# Start date (edits before that date will be ignored)\n",
        "start_date=\"2000-01-01\"\n",
        "\n",
        "# Do not report the article data\n",
        "ignore_article_data = False\n",
        "\n",
        "# Output file\n",
        "output_file = \"wikipedia-edits.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SCRIPT"
      ],
      "metadata": {
        "id": "GhL_BGTbd1Mh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install and import libraries\n",
        "This notebook draws on existing code.\n",
        "You can ignore the output."
      ],
      "metadata": {
        "id": "Q2vEj1G1d25v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In this cell Jupyter checks whether you have the right libraries installed \n",
        "\n",
        "import sys\n",
        "\n",
        "try: #First, Jupyter tries to import a library\n",
        "  import requests\n",
        "  print(\"Requests library has been imported\")\n",
        "except: #If it fails, it will try to install the library\n",
        "  print(\"Requests library not found. Installing...\")\n",
        "  !pip install requests\n",
        "  try:#... and try to import it again\n",
        "      import requests\n",
        "  except: #unless it fails, and raises an error.\n",
        "      print(\"Something went wrong in the installation of the requests library. Please check your internet connection and consult output from the installation below\")\n",
        "\n",
        "try: #First, Jupyter tries to import a library\n",
        "  import geolite2\n",
        "  print(\"geolite2 library has been imported\")\n",
        "except: #If it fails, it will try to install the library\n",
        "  print(\"geolite2 library not found. Installing...\")\n",
        "  !pip install maxminddb-geolite2\n",
        "  try:#... and try to import it again\n",
        "    import geolite2\n",
        "  except: #unless it fails, and raises an error.\n",
        "    print(\"Something went wrong in the installation of the geolite2 library. Please check your internet connection and consult output from the installation below\")\n",
        "\n",
        "# Install (if needed)\n",
        "!pip install pandas\n",
        "\n",
        "# Import\n",
        "import pandas as pd\n",
        "import csv\n",
        "import re"
      ],
      "metadata": {
        "id": "UF-lH31dd4q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read the input file"
      ],
      "metadata": {
        "id": "li-nOSF2ewKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "article_df = pd.read_csv(input_file, quotechar='\"', encoding='utf8', doublequote=True, quoting=csv.QUOTE_NONNUMERIC, dtype=object)\n",
        "print(\"Preview of the article list:\")\n",
        "article_df"
      ],
      "metadata": {
        "id": "h6bZkpLmewnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Harvest the list of edits"
      ],
      "metadata": {
        "id": "s92_WKm3jZcx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Language\n",
        "lan = \"en\"\n",
        "\n",
        "S = requests.Session()\n",
        "revisions=[]\n",
        "count = 1\n",
        "\n",
        "print(\"Starting harvest of revision history for \"+str(len(article_df.index))+\" pages\")\n",
        "for title in article_df[article_name_column]:\n",
        "  Revisions=[]\n",
        "\n",
        "  print(\"Harvesting revision history for \"+title+\" (\"+str(count)+\"/\"+str(len(article_df.index))+\")\")    \n",
        "  URL = \"http://\"+lan+\".wikipedia.org/w/api.php\"\n",
        "\n",
        "  PARAMS = {\n",
        "    \"action\": \"query\",\n",
        "    \"prop\": \"revisions\",\n",
        "    \"titles\": title,\n",
        "    \"rvlimit\": \"500\",\n",
        "    \"rvprop\": \"timestamp|user|comment|slotsize|userid|ids|tags\",\n",
        "    \"rvdir\": \"newer\",\n",
        "    \"rvstart\": start_date+\"T00:00:00Z\",\n",
        "    \"formatversion\": \"2\",\n",
        "    \"format\": \"json\"\n",
        "  }\n",
        "  R = S.get(url=URL, params=PARAMS)\n",
        "  if R.status_code==404:\n",
        "    print(\"The page does not exist\")\n",
        "  DATA = R.json()\n",
        "  for each in DATA['query']['pages']:\n",
        "    Revisions.append(each)\n",
        "  while 'continue' in DATA.keys():\n",
        "    PARAMS = {\n",
        "      \"action\": \"query\",\n",
        "      \"prop\": \"revisions\",\n",
        "      \"titles\": title,\n",
        "      \"rvlimit\": \"500\",\n",
        "      \"rvprop\": \"timestamp|user|comment|slotsize|userid|ids|tags\",\n",
        "      \"rvdir\": \"newer\",\n",
        "      \"rvstart\": start_date+\"T00:00:00Z\",\n",
        "      \"formatversion\": \"2\",\n",
        "      \"format\": \"json\",\n",
        "      \"rvcontinue\": DATA['continue']['rvcontinue']\n",
        "\n",
        "    }\n",
        "\n",
        "    R = S.get(url=URL, params=PARAMS)\n",
        "    DATA = R.json()\n",
        "    for each in DATA['query']['pages']:\n",
        "      Revisions.append(each)\n",
        "\n",
        "  for each in Revisions:\n",
        "    if \"revisions\" in each:\n",
        "      for every in each[\"revisions\"]:\n",
        "        if not \"user\" in every:\n",
        "          every[\"user\"]=\"n/a\"\n",
        "        if not \"userid\" in every:\n",
        "          every[\"userid\"]=\"n/a\"\n",
        "        if not \"comment\" in every:\n",
        "          every[\"comment\"]=\"n/a\"\n",
        "        if not \"slotsize\" in every:\n",
        "          every[\"slotsize\"]=\"n/a\"\n",
        "        if not \"tags\" in every:\n",
        "          every[\"tags\"]=\"n/a\"\n",
        "        if not \"revid\" in every:\n",
        "          every[\"revid\"]=\"n/a\"\n",
        "        if not \"parentid\" in every:\n",
        "          every[\"parentid\"]=\"n/a\"\n",
        "        every[\"page\"]=title\n",
        "\n",
        "        revisions.append(every)\n",
        "  count += 1\n",
        "print(\"Done.\")"
      ],
      "metadata": {
        "id": "6y8cNA1Uf5He"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Enrich edits with geo data"
      ],
      "metadata": {
        "id": "GTfs7pL_jdCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from geolite2 import geolite2\n",
        "reader = geolite2.reader()\n",
        "for rev in revisions:\n",
        "  user=rev[\"user\"]\n",
        "  if re.match(r\"^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}$\",user):\n",
        "    try:\n",
        "      geo=(reader.get(user))\n",
        "      if \"location\" in geo: \n",
        "        lat=geo[\"location\"][\"latitude\"]\n",
        "        long=geo[\"location\"][\"longitude\"]\n",
        "      else: \n",
        "        lat=\"\"\n",
        "        long=\"\"\n",
        "    except:\n",
        "      lat=\"\"\n",
        "      long=\"\"\n",
        "  else:\n",
        "    lat=\"\"\n",
        "    long=\"\"\n",
        "  rev[\"latitude\"]=lat\n",
        "  rev[\"longitude\"]=long\n",
        "print(\"Done.\")"
      ],
      "metadata": {
        "id": "xI6wgan-jg-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Report article data to edits list"
      ],
      "metadata": {
        "id": "GNHfXFoymeHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not ignore_article_data:\n",
        "  # Build index of articles\n",
        "  article_index = {}\n",
        "  for index, row in article_df.iterrows():\n",
        "    title = row[article_name_column]\n",
        "    article_index[title] = row\n",
        "\n",
        "  # Enrich edits with this data.\n",
        "  # Note: we add the prefix \"article-\" to avoid confusion with revision data\n",
        "  for rev in revisions:\n",
        "    article_data = article_index[rev['page']]\n",
        "    for k in article_data.keys():\n",
        "      if k != \"Article\":\n",
        "        rev['article-'+str(k)] = article_data[k]\n",
        "      else:\n",
        "        rev['Article'] = article_data[k]"
      ],
      "metadata": {
        "id": "L2814MpImidk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Monitor revision data"
      ],
      "metadata": {
        "id": "qWLpv2prk-Ab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "revisions_df = pd.DataFrame(revisions)\n",
        "revisions_df = revisions_df.drop(columns=['anon', 'slotsize'])\n",
        "print(\"Preview of the list of edits:\")\n",
        "revisions_df"
      ],
      "metadata": {
        "id": "nUVZONaLlBLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save as CSV"
      ],
      "metadata": {
        "id": "0HipqNp5i7sw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  revisions_df.to_csv(output_file, index = False, encoding='utf-8')\n",
        "  print(\"Done.\")\n",
        "except IOError:\n",
        "  print(\"/!\\ Error while writing the output file\")"
      ],
      "metadata": {
        "id": "RIwPrfTKiXiF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}