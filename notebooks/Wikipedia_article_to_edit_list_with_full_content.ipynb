{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wikipedia article to edit list with full content",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacomyma/mapping-controversies/blob/main/notebooks/Wikipedia_article_to_edit_list_with_full_content.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üç™ Wikipedia article to edit list with full content"
      ],
      "metadata": {
        "id": "JusW97SUGBgc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inputs:**\n",
        "* a Wikipedia article name\n",
        "\n",
        "**Outputs:**\n",
        "* a list of term-revision pairs, with article and timestamp (CSV)\n",
        "\n",
        "This script tells you which words are in which revisions for which article, and when."
      ],
      "metadata": {
        "id": "31PaqnfcGDWB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to use"
      ],
      "metadata": {
        "id": "cVzHKii6HvCw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Edit the settings (at least the article name).\n",
        "1. Run all the cells\n",
        "1. Take the output file from the notebook folder"
      ],
      "metadata": {
        "id": "yiVPSZzJHz22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SETTINGS"
      ],
      "metadata": {
        "id": "2aMAjhGDH2qH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input Wikipedia article\n",
        "input_article = \"Cookie\"\n",
        "\n",
        "# Start date\n",
        "startdate = \"2010-01-01\"\n",
        "\n",
        "# Output files\n",
        "output_file = \"revisions.csv\""
      ],
      "metadata": {
        "id": "ODgqeaStH3kD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SCRIPT"
      ],
      "metadata": {
        "id": "9d_s_6zbH40x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install and import libraries\n",
        "This notebook draws on existing code.\n",
        "You can ignore the output."
      ],
      "metadata": {
        "id": "Swaxx6G4H8yS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU-bf9BtvSJN"
      },
      "source": [
        "# Install (if needed)\n",
        "!pip install pandas\n",
        "!pip install requests\n",
        "\n",
        "# Import\n",
        "import csv\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "print(\"Done.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Harvest Wikipedia"
      ],
      "metadata": {
        "id": "eczPM9TFMO3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a dump for security\n",
        "dump_filename = \"dump-data.csv\"\n",
        "\n",
        "# Define an empty dataframe for the output datafile\n",
        "df = pd.DataFrame(columns=['Page','OldRevision_Url','Time','Text'])\n",
        "\n",
        "URL = \"http://en.wikipedia.org/w/api.php\" # we are going to call the API for English Wikipedia\n",
        "S = requests.Session()\n",
        "  \n",
        "# Below some paramters for the API query. We are getting the ID and timestamp for each revision.\n",
        "PARAMS = {\n",
        "  \"action\": \"query\",\n",
        "  \"prop\": \"revisions\",\n",
        "  \"titles\": input_article,\n",
        "  \"rvlimit\": \"500\",\n",
        "  \"rvprop\": \"timestamp|ids|content\",\n",
        "  \"rvdir\": \"newer\",\n",
        "  \"rvstart\": startdate+\"T00:00:00Z\",\n",
        "  \"formatversion\": \"2\",\n",
        "  \"format\": \"json\"\n",
        "}\n",
        "\n",
        "R = S.get(url=URL, params=PARAMS)\n",
        "if R.status_code==404:\n",
        "  print(\"The page does not exist\")\n",
        "DATA = R.json()\n",
        "for each in DATA['query']['pages']:\n",
        "  for revision in each['revisions']:\n",
        "    row = [input_article,'https://en.wikipedia.org/w/index.php?title='+input_article+'&oldid='+str(revision['revid']),revision['timestamp'], revision['content']]\n",
        "    df.loc[len(df)] = row\n",
        "\n",
        "  # Dump the latest version of the reuslts\n",
        "  df.to_csv(dump_filename)\n",
        "  print('Queried another 500 revisions until for ' + input_article + ''+revision['timestamp'])\n",
        "\n",
        "# When there are more than 500 revisions we need this addition to keep paging through the revisions.\n",
        "while 'continue' in DATA.keys():\n",
        "  PARAMS = {\n",
        "    \"action\": \"query\",\n",
        "    \"prop\": \"revisions\",\n",
        "    \"titles\": input_article,\n",
        "    \"rvlimit\": \"500\",\n",
        "    \"rvprop\": \"timestamp|ids|content\",\n",
        "    \"rvdir\": \"newer\",\n",
        "    \"rvstart\": startdate+\"T00:00:00Z\",\n",
        "    \"formatversion\": \"2\",\n",
        "    \"format\": \"json\",\n",
        "    \"rvcontinue\": DATA['continue']['rvcontinue']\n",
        "  }\n",
        "\n",
        "  R = S.get(url=URL, params=PARAMS)\n",
        "  DATA = R.json()\n",
        "  for each in DATA['query']['pages']:\n",
        "    for revision in each['revisions']:\n",
        "      row = [input_article,'https://en.wikipedia.org/w/index.php?title='+input_article+'&oldid='+str(revision['revid']),revision['timestamp'], revision['content']]\n",
        "      df.loc[len(df)] = row\n",
        "\n",
        "  # Dump the latest version of the reuslts\n",
        "  df.to_csv(dump_filename)\n",
        "  print('Queried another 500 revisions for ' + input_article + ' until '+revision['timestamp'])\n",
        "\n",
        "print('Done.')"
      ],
      "metadata": {
        "id": "HA_qnH03MRBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save the CSV"
      ],
      "metadata": {
        "id": "aghyPKIpsHDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  df.to_csv(output_file, index = False, encoding='utf-8')\n",
        "  print('Done.')\n",
        "except IOError:\n",
        "  print(\"/!\\ Error while writing the output file\")"
      ],
      "metadata": {
        "id": "48D2D2llsItf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}